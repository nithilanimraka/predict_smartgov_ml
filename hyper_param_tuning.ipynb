{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cda40489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import (\n",
    "                                    StratifiedKFold, \n",
    "                                    GridSearchCV\n",
    "                                    )\n",
    "from sklearn.metrics import confusion_matrix\n",
    "warnings.filterwarnings('ignore')\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "530b7f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('artifacts/X_train.npz')['arr_0']\n",
    "y_train = np.load('artifacts/Y_train.npz')['arr_0']\n",
    "X_test = np.load('artifacts/X_test.npz')['arr_0']\n",
    "y_test = np.load('artifacts/Y_test.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1d1334f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-22 18:46:32,134] A new study created in memory with name: no-name-12fd8c3b-c0f2-464b-8e67-9de960dc60c5\n",
      "[I 2025-08-22 18:46:33,283] Trial 0 finished with value: -8.59860913474613 and parameters: {'n_estimators': 137, 'max_depth': 4, 'learning_rate': 0.05736471246712876, 'subsample': 0.6251576614466313, 'colsample_bytree': 0.8675635519038313}. Best is trial 0 with value: -8.59860913474613.\n",
      "[I 2025-08-22 18:46:36,228] Trial 1 finished with value: -8.615926880076085 and parameters: {'n_estimators': 163, 'max_depth': 9, 'learning_rate': 0.021202518837642337, 'subsample': 0.7325469665025984, 'colsample_bytree': 0.9688243176182938}. Best is trial 0 with value: -8.59860913474613.\n",
      "[I 2025-08-22 18:46:37,015] Trial 2 finished with value: -8.554287588370297 and parameters: {'n_estimators': 81, 'max_depth': 5, 'learning_rate': 0.08605418679923313, 'subsample': 0.8097779517945465, 'colsample_bytree': 0.812217570389743}. Best is trial 2 with value: -8.554287588370297.\n",
      "[I 2025-08-22 18:46:44,414] Trial 3 finished with value: -8.65123528243472 and parameters: {'n_estimators': 287, 'max_depth': 12, 'learning_rate': 0.05169514422683209, 'subsample': 0.8413632508764661, 'colsample_bytree': 0.6149934469950911}. Best is trial 2 with value: -8.554287588370297.\n",
      "[I 2025-08-22 18:46:56,376] Trial 4 finished with value: -9.020130010973071 and parameters: {'n_estimators': 195, 'max_depth': 16, 'learning_rate': 0.11238279849611181, 'subsample': 0.6926469453492304, 'colsample_bytree': 0.8685642428381672}. Best is trial 2 with value: -8.554287588370297.\n",
      "[I 2025-08-22 18:46:58,719] Trial 5 finished with value: -8.805906641204588 and parameters: {'n_estimators': 90, 'max_depth': 11, 'learning_rate': 0.1975519393380378, 'subsample': 0.8673904265568088, 'colsample_bytree': 0.803358960850026}. Best is trial 2 with value: -8.554287588370297.\n",
      "[I 2025-08-22 18:47:00,530] Trial 6 finished with value: -8.948588755787497 and parameters: {'n_estimators': 82, 'max_depth': 10, 'learning_rate': 0.026266164731820668, 'subsample': 0.6624492420021216, 'colsample_bytree': 0.8534051165333638}. Best is trial 2 with value: -8.554287588370297.\n",
      "[I 2025-08-22 18:47:11,080] Trial 7 finished with value: -8.914031299374901 and parameters: {'n_estimators': 267, 'max_depth': 13, 'learning_rate': 0.12653658333062587, 'subsample': 0.8882138362738234, 'colsample_bytree': 0.8129799343866995}. Best is trial 2 with value: -8.554287588370297.\n",
      "[I 2025-08-22 18:47:12,374] Trial 8 finished with value: -8.534802935461334 and parameters: {'n_estimators': 105, 'max_depth': 7, 'learning_rate': 0.1464334277853602, 'subsample': 0.9584669089117436, 'colsample_bytree': 0.8338931297569243}. Best is trial 8 with value: -8.534802935461334.\n",
      "[I 2025-08-22 18:47:14,147] Trial 9 finished with value: -9.044136549289743 and parameters: {'n_estimators': 205, 'max_depth': 5, 'learning_rate': 0.017511646404239765, 'subsample': 0.7283781006364834, 'colsample_bytree': 0.7016946624763419}. Best is trial 8 with value: -8.534802935461334.\n",
      "[I 2025-08-22 18:47:14,900] Trial 10 finished with value: -8.53442325571675 and parameters: {'n_estimators': 53, 'max_depth': 7, 'learning_rate': 0.16737025746877376, 'subsample': 0.9904340445992053, 'colsample_bytree': 0.9795402915106568}. Best is trial 10 with value: -8.53442325571675.\n",
      "[I 2025-08-22 18:47:15,606] Trial 11 finished with value: -8.534144524738934 and parameters: {'n_estimators': 51, 'max_depth': 7, 'learning_rate': 0.16598347150762044, 'subsample': 0.992697991946343, 'colsample_bytree': 0.9891697212567288}. Best is trial 11 with value: -8.534144524738934.\n",
      "[I 2025-08-22 18:47:16,439] Trial 12 finished with value: -8.540086054179538 and parameters: {'n_estimators': 63, 'max_depth': 7, 'learning_rate': 0.17779292295245502, 'subsample': 0.9955394384410816, 'colsample_bytree': 0.9785768200877806}. Best is trial 11 with value: -8.534144524738934.\n",
      "[I 2025-08-22 18:47:17,272] Trial 13 finished with value: -8.55678662285678 and parameters: {'n_estimators': 52, 'max_depth': 8, 'learning_rate': 0.15840558370169533, 'subsample': 0.938852268141596, 'colsample_bytree': 0.9375587546990708}. Best is trial 11 with value: -8.534144524738934.\n",
      "[I 2025-08-22 18:47:18,550] Trial 14 finished with value: -8.559852901211396 and parameters: {'n_estimators': 121, 'max_depth': 6, 'learning_rate': 0.19807453185147553, 'subsample': 0.9232729759246304, 'colsample_bytree': 0.9994990527814457}. Best is trial 11 with value: -8.534144524738934.\n",
      "[I 2025-08-22 18:47:19,906] Trial 15 finished with value: -8.464100448238716 and parameters: {'n_estimators': 230, 'max_depth': 3, 'learning_rate': 0.15899985296147212, 'subsample': 0.9986612457973107, 'colsample_bytree': 0.9070288865211775}. Best is trial 15 with value: -8.464100448238716.\n",
      "[I 2025-08-22 18:47:21,303] Trial 16 finished with value: -8.461010621800998 and parameters: {'n_estimators': 235, 'max_depth': 3, 'learning_rate': 0.13354069769047136, 'subsample': 0.9065313992948696, 'colsample_bytree': 0.7479060048138901}. Best is trial 16 with value: -8.461010621800998.\n",
      "[I 2025-08-22 18:47:22,747] Trial 17 finished with value: -8.460035736719979 and parameters: {'n_estimators': 243, 'max_depth': 3, 'learning_rate': 0.13337195339756922, 'subsample': 0.8987725178936958, 'colsample_bytree': 0.7444684124381443}. Best is trial 17 with value: -8.460035736719979.\n",
      "[I 2025-08-22 18:47:24,188] Trial 18 finished with value: -8.456415730624599 and parameters: {'n_estimators': 243, 'max_depth': 3, 'learning_rate': 0.12988378812739979, 'subsample': 0.9054883462989392, 'colsample_bytree': 0.7421177841851508}. Best is trial 18 with value: -8.456415730624599.\n",
      "[I 2025-08-22 18:47:25,695] Trial 19 finished with value: -8.477879422771164 and parameters: {'n_estimators': 245, 'max_depth': 3, 'learning_rate': 0.08172648585091401, 'subsample': 0.798854566822512, 'colsample_bytree': 0.73858114090802}. Best is trial 18 with value: -8.456415730624599.\n",
      "[I 2025-08-22 18:47:28,099] Trial 20 finished with value: -8.494427141968908 and parameters: {'n_estimators': 284, 'max_depth': 5, 'learning_rate': 0.09849118931407232, 'subsample': 0.8322510826218293, 'colsample_bytree': 0.6519797995463705}. Best is trial 18 with value: -8.456415730624599.\n",
      "[I 2025-08-22 18:47:29,503] Trial 21 finished with value: -8.460480084663825 and parameters: {'n_estimators': 235, 'max_depth': 3, 'learning_rate': 0.126452750765191, 'subsample': 0.9002597041800631, 'colsample_bytree': 0.7512590508126791}. Best is trial 18 with value: -8.456415730624599.\n",
      "[I 2025-08-22 18:47:31,013] Trial 22 finished with value: -8.476147568219279 and parameters: {'n_estimators': 209, 'max_depth': 4, 'learning_rate': 0.12834699429326601, 'subsample': 0.8816394675565233, 'colsample_bytree': 0.7577872182137979}. Best is trial 18 with value: -8.456415730624599.\n",
      "[I 2025-08-22 18:47:32,769] Trial 23 finished with value: -8.475645359918154 and parameters: {'n_estimators': 247, 'max_depth': 4, 'learning_rate': 0.11200270350824931, 'subsample': 0.9480292247197685, 'colsample_bytree': 0.6934132908357362}. Best is trial 18 with value: -8.456415730624599.\n",
      "[I 2025-08-22 18:47:34,358] Trial 24 finished with value: -8.45324725657378 and parameters: {'n_estimators': 264, 'max_depth': 3, 'learning_rate': 0.14135611231295486, 'subsample': 0.772327740114096, 'colsample_bytree': 0.7695700521749886}. Best is trial 24 with value: -8.45324725657378.\n",
      "[I 2025-08-22 18:47:36,634] Trial 25 finished with value: -8.518595230095238 and parameters: {'n_estimators': 265, 'max_depth': 5, 'learning_rate': 0.14559897155045545, 'subsample': 0.7826011355538552, 'colsample_bytree': 0.6963328641695964}. Best is trial 24 with value: -8.45324725657378.\n",
      "[I 2025-08-22 18:47:49,654] Trial 26 finished with value: -9.114231225862136 and parameters: {'n_estimators': 300, 'max_depth': 14, 'learning_rate': 0.14166843059260045, 'subsample': 0.7482936718330907, 'colsample_bytree': 0.7197302523565858}. Best is trial 24 with value: -8.45324725657378.\n",
      "[I 2025-08-22 18:47:51,318] Trial 27 finished with value: -8.503460921083839 and parameters: {'n_estimators': 162, 'max_depth': 6, 'learning_rate': 0.10230234026007132, 'subsample': 0.8446551615749421, 'colsample_bytree': 0.7712731259101451}. Best is trial 24 with value: -8.45324725657378.\n",
      "[I 2025-08-22 18:47:53,248] Trial 28 finished with value: -8.495519084910054 and parameters: {'n_estimators': 264, 'max_depth': 4, 'learning_rate': 0.18185457569058255, 'subsample': 0.7617746919906785, 'colsample_bytree': 0.7839817246026093}. Best is trial 24 with value: -8.45324725657378.\n",
      "[I 2025-08-22 18:47:54,873] Trial 29 finished with value: -8.471540479141394 and parameters: {'n_estimators': 217, 'max_depth': 4, 'learning_rate': 0.11708723230209778, 'subsample': 0.6960868402872733, 'colsample_bytree': 0.6649233750236926}. Best is trial 24 with value: -8.45324725657378.\n",
      "[I 2025-08-22 18:47:56,758] Trial 30 finished with value: -8.496580519276431 and parameters: {'n_estimators': 186, 'max_depth': 6, 'learning_rate': 0.08725566183390124, 'subsample': 0.820553771020922, 'colsample_bytree': 0.6618104214123717}. Best is trial 24 with value: -8.45324725657378.\n",
      "[I 2025-08-22 18:47:58,111] Trial 31 finished with value: -8.458933929487745 and parameters: {'n_estimators': 224, 'max_depth': 3, 'learning_rate': 0.12633991580215265, 'subsample': 0.8643416517274551, 'colsample_bytree': 0.7396040911696455}. Best is trial 24 with value: -8.45324725657378.\n",
      "[I 2025-08-22 18:47:59,621] Trial 32 finished with value: -8.462524462731178 and parameters: {'n_estimators': 254, 'max_depth': 3, 'learning_rate': 0.14155903118306712, 'subsample': 0.8646738799903655, 'colsample_bytree': 0.7305649588710632}. Best is trial 24 with value: -8.45324725657378.\n",
      "[I 2025-08-22 18:48:01,045] Trial 33 finished with value: -8.457522182520083 and parameters: {'n_estimators': 222, 'max_depth': 3, 'learning_rate': 0.15340367862218973, 'subsample': 0.8568260914760263, 'colsample_bytree': 0.7797009963085125}. Best is trial 24 with value: -8.45324725657378.\n",
      "[I 2025-08-22 18:48:02,500] Trial 34 finished with value: -8.500743489511422 and parameters: {'n_estimators': 164, 'max_depth': 5, 'learning_rate': 0.15082845829664948, 'subsample': 0.7882303056772938, 'colsample_bytree': 0.7859747410039483}. Best is trial 24 with value: -8.45324725657378.\n",
      "[I 2025-08-22 18:48:06,190] Trial 35 finished with value: -8.581084844873734 and parameters: {'n_estimators': 223, 'max_depth': 9, 'learning_rate': 0.06697547312137755, 'subsample': 0.8512051586118228, 'colsample_bytree': 0.8351440104370367}. Best is trial 24 with value: -8.45324725657378.\n",
      "[I 2025-08-22 18:48:07,644] Trial 36 finished with value: -8.4712283349326 and parameters: {'n_estimators': 184, 'max_depth': 4, 'learning_rate': 0.11853153542694486, 'subsample': 0.6236261055751922, 'colsample_bytree': 0.781622919533562}. Best is trial 24 with value: -8.45324725657378.\n",
      "[I 2025-08-22 18:48:08,766] Trial 37 finished with value: -8.482276846668217 and parameters: {'n_estimators': 145, 'max_depth': 4, 'learning_rate': 0.180585586075223, 'subsample': 0.8172326116688124, 'colsample_bytree': 0.6002544522460572}. Best is trial 24 with value: -8.45324725657378.\n",
      "[I 2025-08-22 18:48:11,602] Trial 38 finished with value: -8.526392231502328 and parameters: {'n_estimators': 279, 'max_depth': 6, 'learning_rate': 0.09216584710648323, 'subsample': 0.8653843829002966, 'colsample_bytree': 0.8807965655461784}. Best is trial 24 with value: -8.45324725657378.\n",
      "[I 2025-08-22 18:48:21,724] Trial 39 finished with value: -8.797294994980552 and parameters: {'n_estimators': 198, 'max_depth': 15, 'learning_rate': 0.07402113974035386, 'subsample': 0.7717303473572388, 'colsample_bytree': 0.8114160250441428}. Best is trial 24 with value: -8.45324725657378.\n",
      "[I 2025-08-22 18:48:28,736] Trial 40 finished with value: -8.618191203932696 and parameters: {'n_estimators': 300, 'max_depth': 11, 'learning_rate': 0.04698711393806878, 'subsample': 0.717564350394122, 'colsample_bytree': 0.7179103430079573}. Best is trial 24 with value: -8.45324725657378.\n",
      "[I 2025-08-22 18:48:30,219] Trial 41 finished with value: -8.46358188445291 and parameters: {'n_estimators': 256, 'max_depth': 3, 'learning_rate': 0.13467539185216407, 'subsample': 0.9197069584227813, 'colsample_bytree': 0.761557049410692}. Best is trial 24 with value: -8.45324725657378.\n",
      "[I 2025-08-22 18:48:31,510] Trial 42 finished with value: -8.452786374061379 and parameters: {'n_estimators': 217, 'max_depth': 3, 'learning_rate': 0.15414785835129766, 'subsample': 0.8831953859498567, 'colsample_bytree': 0.8022172245813096}. Best is trial 42 with value: -8.452786374061379.\n",
      "[I 2025-08-22 18:48:33,342] Trial 43 finished with value: -8.516680370951496 and parameters: {'n_estimators': 215, 'max_depth': 5, 'learning_rate': 0.15644192472210852, 'subsample': 0.8669645078405853, 'colsample_bytree': 0.8326154422153471}. Best is trial 42 with value: -8.452786374061379.\n",
      "[I 2025-08-22 18:48:35,262] Trial 44 finished with value: -8.498819864907171 and parameters: {'n_estimators': 274, 'max_depth': 4, 'learning_rate': 0.16854737044462972, 'subsample': 0.9678684260785544, 'colsample_bytree': 0.7969822378014895}. Best is trial 42 with value: -8.452786374061379.\n",
      "[I 2025-08-22 18:48:36,839] Trial 45 finished with value: -8.453086435923439 and parameters: {'n_estimators': 224, 'max_depth': 3, 'learning_rate': 0.15147866783890296, 'subsample': 0.8804742839407267, 'colsample_bytree': 0.8239232302447341}. Best is trial 42 with value: -8.452786374061379.\n",
      "[I 2025-08-22 18:48:38,598] Trial 46 finished with value: -8.517739868093836 and parameters: {'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.1735190587527941, 'subsample': 0.8832796641484608, 'colsample_bytree': 0.8559071669116247}. Best is trial 42 with value: -8.452786374061379.\n",
      "[I 2025-08-22 18:48:39,857] Trial 47 finished with value: -8.462005264075476 and parameters: {'n_estimators': 205, 'max_depth': 3, 'learning_rate': 0.18701160697271482, 'subsample': 0.8261814996913088, 'colsample_bytree': 0.8243303015870415}. Best is trial 42 with value: -8.452786374061379.\n",
      "[I 2025-08-22 18:48:43,528] Trial 48 finished with value: -8.711036838276005 and parameters: {'n_estimators': 256, 'max_depth': 8, 'learning_rate': 0.1526617876837374, 'subsample': 0.927102738957822, 'colsample_bytree': 0.8948723496581832}. Best is trial 42 with value: -8.452786374061379.\n",
      "[I 2025-08-22 18:48:45,295] Trial 49 finished with value: -8.492475305586257 and parameters: {'n_estimators': 237, 'max_depth': 4, 'learning_rate': 0.16546310351707427, 'subsample': 0.6426308782269553, 'colsample_bytree': 0.799313706290031}. Best is trial 42 with value: -8.452786374061379.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost Params: {'n_estimators': 217, 'max_depth': 3, 'learning_rate': 0.15414785835129766, 'subsample': 0.8831953859498567, 'colsample_bytree': 0.8022172245813096}\n",
      "Best XGBoost MAE Score: 8.452786374061379\n",
      "Best XGBoost MAE: 8.4528\n"
     ]
    }
   ],
   "source": [
    "# Function for Optuna objective (example for XGBoost; repeat for others)\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 16),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    \n",
    "    # CV on logged y, but score on inverse for MAE\n",
    "    def custom_scorer(estimator, X, y):\n",
    "        preds_log = estimator.predict(X)\n",
    "        preds = np.expm1(preds_log)\n",
    "        y_orig = np.expm1(y)\n",
    "        return -mean_absolute_error(y_orig, preds)  # Neg for minimization\n",
    "    \n",
    "    # Use TimeSeriesSplit instead of random cv=5\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=tscv, scoring=custom_scorer)\n",
    "    return score.mean()\n",
    "\n",
    "# Run Optuna \n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(objective_xgb, n_trials=50)\n",
    "best_params_xgb = study_xgb.best_params\n",
    "best_value_xgb = study_xgb.best_value\n",
    "\n",
    "print(\"Best XGBoost Params:\", best_params_xgb)\n",
    "print(\"Best XGBoost MAE Score:\", -best_value_xgb)  # Convert back to positive MAE\n",
    "print(f\"Best XGBoost MAE: {-best_value_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78a86eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-22 18:48:45,302] A new study created in memory with name: no-name-e780bd33-1169-427f-a510-a3bd2c1a654c\n",
      "[I 2025-08-22 18:48:47,203] Trial 0 finished with value: -8.485991628177407 and parameters: {'n_estimators': 69, 'max_depth': 16, 'learning_rate': 0.16679793316993355, 'subsample': 0.6075999142415109, 'colsample_bytree': 0.759698502317446}. Best is trial 0 with value: -8.485991628177407.\n",
      "[I 2025-08-22 18:48:49,168] Trial 1 finished with value: -8.520525816040927 and parameters: {'n_estimators': 79, 'max_depth': 14, 'learning_rate': 0.2606850437964723, 'subsample': 0.67964193199874, 'colsample_bytree': 0.7326456362879937}. Best is trial 0 with value: -8.485991628177407.\n",
      "[I 2025-08-22 18:48:55,187] Trial 2 finished with value: -8.576176683220869 and parameters: {'n_estimators': 265, 'max_depth': 9, 'learning_rate': 0.23436145912913464, 'subsample': 0.921602482086893, 'colsample_bytree': 0.7994724943460797}. Best is trial 0 with value: -8.485991628177407.\n",
      "[I 2025-08-22 18:48:55,679] Trial 3 finished with value: -8.526514322984632 and parameters: {'n_estimators': 63, 'max_depth': 3, 'learning_rate': 0.21551873978455585, 'subsample': 0.7561736953421114, 'colsample_bytree': 0.8215135104905266}. Best is trial 0 with value: -8.485991628177407.\n",
      "[I 2025-08-22 18:49:02,363] Trial 4 finished with value: -8.552210566587888 and parameters: {'n_estimators': 279, 'max_depth': 14, 'learning_rate': 0.2078328386960128, 'subsample': 0.6899362319036025, 'colsample_bytree': 0.7100947764147871}. Best is trial 0 with value: -8.485991628177407.\n",
      "[I 2025-08-22 18:49:04,671] Trial 5 finished with value: -8.499222334219203 and parameters: {'n_estimators': 91, 'max_depth': 11, 'learning_rate': 0.21670954239500004, 'subsample': 0.6583554817923762, 'colsample_bytree': 0.7845035466164314}. Best is trial 0 with value: -8.485991628177407.\n",
      "[I 2025-08-22 18:49:07,551] Trial 6 finished with value: -8.539652358928867 and parameters: {'n_estimators': 123, 'max_depth': 12, 'learning_rate': 0.2677024514765428, 'subsample': 0.6089572640050799, 'colsample_bytree': 0.8762335423962503}. Best is trial 0 with value: -8.485991628177407.\n",
      "[I 2025-08-22 18:49:08,481] Trial 7 finished with value: -8.463817999518277 and parameters: {'n_estimators': 140, 'max_depth': 3, 'learning_rate': 0.2599855943525703, 'subsample': 0.8653157639528063, 'colsample_bytree': 0.6996016591440931}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:49:12,568] Trial 8 finished with value: -8.525535140782354 and parameters: {'n_estimators': 195, 'max_depth': 6, 'learning_rate': 0.1762325957265477, 'subsample': 0.9703465988425944, 'colsample_bytree': 0.808384262448332}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:49:14,020] Trial 9 finished with value: -8.475326535201772 and parameters: {'n_estimators': 53, 'max_depth': 12, 'learning_rate': 0.18511356004967322, 'subsample': 0.77842424997898, 'colsample_bytree': 0.9075907445040243}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:49:15,085] Trial 10 finished with value: -8.478187422314353 and parameters: {'n_estimators': 160, 'max_depth': 3, 'learning_rate': 0.29728001231819123, 'subsample': 0.8777533583709394, 'colsample_bytree': 0.6007163035213283}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:49:19,432] Trial 11 finished with value: -8.526709562158732 and parameters: {'n_estimators': 202, 'max_depth': 8, 'learning_rate': 0.145255595461012, 'subsample': 0.8227342808635729, 'colsample_bytree': 0.9571157344248845}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:49:22,472] Trial 12 finished with value: -8.495905779592558 and parameters: {'n_estimators': 146, 'max_depth': 6, 'learning_rate': 0.1074334980562809, 'subsample': 0.7921749397460291, 'colsample_bytree': 0.9714867420628212}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:49:27,124] Trial 13 finished with value: -8.563116312576373 and parameters: {'n_estimators': 238, 'max_depth': 6, 'learning_rate': 0.24803458783168592, 'subsample': 0.81057304858316, 'colsample_bytree': 0.6695024981768558}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:49:29,858] Trial 14 finished with value: -8.544378343081316 and parameters: {'n_estimators': 113, 'max_depth': 11, 'learning_rate': 0.29375903113953983, 'subsample': 0.8696887048357642, 'colsample_bytree': 0.8885608624070246}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:49:32,730] Trial 15 finished with value: -8.495773529655525 and parameters: {'n_estimators': 120, 'max_depth': 13, 'learning_rate': 0.18417366439497382, 'subsample': 0.7357140737976849, 'colsample_bytree': 0.8949655470562479}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:49:36,785] Trial 16 finished with value: -8.502555907766112 and parameters: {'n_estimators': 188, 'max_depth': 8, 'learning_rate': 0.15051984429659399, 'subsample': 0.8636171092354766, 'colsample_bytree': 0.6369876550866049}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:49:40,905] Trial 17 finished with value: -8.499335951358557 and parameters: {'n_estimators': 224, 'max_depth': 5, 'learning_rate': 0.13162851945262022, 'subsample': 0.9934867832156453, 'colsample_bytree': 0.6811519827057977}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:49:44,441] Trial 18 finished with value: -8.51553252703402 and parameters: {'n_estimators': 149, 'max_depth': 16, 'learning_rate': 0.19499213409960123, 'subsample': 0.9237575830472542, 'colsample_bytree': 0.9989953946929967}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:49:46,952] Trial 19 finished with value: -8.5099643061333 and parameters: {'n_estimators': 102, 'max_depth': 10, 'learning_rate': 0.23599218339336753, 'subsample': 0.7518689815256723, 'colsample_bytree': 0.8470088720376858}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:49:47,618] Trial 20 finished with value: -8.499042004577287 and parameters: {'n_estimators': 54, 'max_depth': 4, 'learning_rate': 0.2742693159589023, 'subsample': 0.9221247176993527, 'colsample_bytree': 0.9363476504120798}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:49:48,666] Trial 21 finished with value: -8.473685703052755 and parameters: {'n_estimators': 159, 'max_depth': 3, 'learning_rate': 0.2997625796994777, 'subsample': 0.859895871487315, 'colsample_bytree': 0.6103496841054755}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:49:50,157] Trial 22 finished with value: -8.498688664683355 and parameters: {'n_estimators': 138, 'max_depth': 4, 'learning_rate': 0.2857210731165495, 'subsample': 0.8436139434144426, 'colsample_bytree': 0.602589452808519}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:49:53,575] Trial 23 finished with value: -8.53809872617035 and parameters: {'n_estimators': 163, 'max_depth': 7, 'learning_rate': 0.2537373840631426, 'subsample': 0.7805059499053332, 'colsample_bytree': 0.6686046684616184}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:49:55,902] Trial 24 finished with value: -8.520166464733274 and parameters: {'n_estimators': 223, 'max_depth': 4, 'learning_rate': 0.2753045153481064, 'subsample': 0.8915996365771546, 'colsample_bytree': 0.6404012088723603}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:49:57,229] Trial 25 finished with value: -8.467097537639559 and parameters: {'n_estimators': 180, 'max_depth': 3, 'learning_rate': 0.23884766759245513, 'subsample': 0.8295682604327038, 'colsample_bytree': 0.7192079564766396}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:49:58,440] Trial 26 finished with value: -8.467646396750249 and parameters: {'n_estimators': 181, 'max_depth': 3, 'learning_rate': 0.23456075170619534, 'subsample': 0.834705850557238, 'colsample_bytree': 0.7182371619944345}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:01,768] Trial 27 finished with value: -8.527016372910634 and parameters: {'n_estimators': 177, 'max_depth': 5, 'learning_rate': 0.23217311590564865, 'subsample': 0.8303920934670518, 'colsample_bytree': 0.7221424046167283}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:05,409] Trial 28 finished with value: -8.534928125676295 and parameters: {'n_estimators': 208, 'max_depth': 5, 'learning_rate': 0.24601453403726115, 'subsample': 0.9036969114992686, 'colsample_bytree': 0.7505712438229002}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:06,554] Trial 29 finished with value: -8.464637055547836 and parameters: {'n_estimators': 175, 'max_depth': 3, 'learning_rate': 0.2279607126440276, 'subsample': 0.715836927663302, 'colsample_bytree': 0.768245627164993}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:09,138] Trial 30 finished with value: -8.500977946378224 and parameters: {'n_estimators': 252, 'max_depth': 4, 'learning_rate': 0.2214891058678002, 'subsample': 0.7344424410737123, 'colsample_bytree': 0.7507785152832447}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:10,283] Trial 31 finished with value: -8.470281034407165 and parameters: {'n_estimators': 175, 'max_depth': 3, 'learning_rate': 0.22975488475320013, 'subsample': 0.8462786989438384, 'colsample_bytree': 0.6957162774896538}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:11,461] Trial 32 finished with value: -8.46852857011022 and parameters: {'n_estimators': 182, 'max_depth': 3, 'learning_rate': 0.2611539455758152, 'subsample': 0.7131474947131009, 'colsample_bytree': 0.7364232119242635}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:13,820] Trial 33 finished with value: -8.512873480586421 and parameters: {'n_estimators': 131, 'max_depth': 5, 'learning_rate': 0.24375139954293146, 'subsample': 0.8050987499845353, 'colsample_bytree': 0.7878666840188486}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:16,059] Trial 34 finished with value: -8.491188429401479 and parameters: {'n_estimators': 217, 'max_depth': 4, 'learning_rate': 0.20840547946853724, 'subsample': 0.6427977661327834, 'colsample_bytree': 0.7686037065608419}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:17,156] Trial 35 finished with value: -8.468302822441618 and parameters: {'n_estimators': 168, 'max_depth': 3, 'learning_rate': 0.2571750255116299, 'subsample': 0.9414104470617757, 'colsample_bytree': 0.7101601406186193}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:20,421] Trial 36 finished with value: -8.530176961935592 and parameters: {'n_estimators': 149, 'max_depth': 7, 'learning_rate': 0.2263359174696732, 'subsample': 0.7763147174327483, 'colsample_bytree': 0.8371875624810653}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:23,448] Trial 37 finished with value: -8.504312722118758 and parameters: {'n_estimators': 294, 'max_depth': 4, 'learning_rate': 0.20443031158348346, 'subsample': 0.6974308544224668, 'colsample_bytree': 0.7714913813016393}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:24,968] Trial 38 finished with value: -8.506800702888077 and parameters: {'n_estimators': 80, 'max_depth': 5, 'learning_rate': 0.24024591900980827, 'subsample': 0.8314122560571442, 'colsample_bytree': 0.7340137820826044}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:26,192] Trial 39 finished with value: -8.469353490933148 and parameters: {'n_estimators': 191, 'max_depth': 3, 'learning_rate': 0.21620763600830079, 'subsample': 0.759320140286272, 'colsample_bytree': 0.6946710943880546}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:31,102] Trial 40 finished with value: -8.594855732731194 and parameters: {'n_estimators': 239, 'max_depth': 7, 'learning_rate': 0.2813075516013043, 'subsample': 0.6720703002309477, 'colsample_bytree': 0.8133166739723933}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:32,207] Trial 41 finished with value: -8.469462701450627 and parameters: {'n_estimators': 169, 'max_depth': 3, 'learning_rate': 0.2584520713579549, 'subsample': 0.9504172679556665, 'colsample_bytree': 0.7041928866010062}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:33,528] Trial 42 finished with value: -8.47312537403336 and parameters: {'n_estimators': 204, 'max_depth': 3, 'learning_rate': 0.2661201976947776, 'subsample': 0.9566790785273919, 'colsample_bytree': 0.7246892385045762}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:34,979] Trial 43 finished with value: -8.491903515007467 and parameters: {'n_estimators': 135, 'max_depth': 4, 'learning_rate': 0.2513036422757664, 'subsample': 0.900736318190927, 'colsample_bytree': 0.6488111076157552}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:38,157] Trial 44 finished with value: -8.517497808306503 and parameters: {'n_estimators': 157, 'max_depth': 6, 'learning_rate': 0.1955071419656563, 'subsample': 0.9436164843580911, 'colsample_bytree': 0.7197653339117727}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:39,280] Trial 45 finished with value: -8.473917470432472 and parameters: {'n_estimators': 173, 'max_depth': 3, 'learning_rate': 0.2680988482695144, 'subsample': 0.9980220169007301, 'colsample_bytree': 0.7485522361983641}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:42,770] Trial 46 finished with value: -8.543705363258258 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.23888760010554388, 'subsample': 0.8854955260352434, 'colsample_bytree': 0.7811826411421241}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:44,714] Trial 47 finished with value: -8.48293743386169 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.2239857225827627, 'subsample': 0.8133418472466696, 'colsample_bytree': 0.6851608067668109}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:45,549] Trial 48 finished with value: -8.480121410374254 and parameters: {'n_estimators': 106, 'max_depth': 3, 'learning_rate': 0.2135120641471659, 'subsample': 0.6236353425806194, 'colsample_bytree': 0.7103181500081834}. Best is trial 7 with value: -8.463817999518277.\n",
      "[I 2025-08-22 18:50:48,509] Trial 49 finished with value: -8.538089365474683 and parameters: {'n_estimators': 144, 'max_depth': 6, 'learning_rate': 0.2600603278892309, 'subsample': 0.8548138925352106, 'colsample_bytree': 0.655495495751383}. Best is trial 7 with value: -8.463817999518277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LightGBM Params: {'n_estimators': 140, 'max_depth': 3, 'learning_rate': 0.2599855943525703, 'subsample': 0.8653157639528063, 'colsample_bytree': 0.6996016591440931}\n",
      "Best LightGBM MAE Score: 8.463817999518277\n",
      "Best LightGBM MAE: 8.4638\n"
     ]
    }
   ],
   "source": [
    "# Repeat for LightGBM\n",
    "def objective_lgb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 16),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.1, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'random_state': 42,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    \n",
    "    # CV on logged y, but score on inverse for MAE\n",
    "    def custom_scorer(estimator, X, y):\n",
    "        preds_log = estimator.predict(X)\n",
    "        preds = np.expm1(preds_log)\n",
    "        y_orig = np.expm1(y)\n",
    "        return -mean_absolute_error(y_orig, preds)  # Neg for minimization\n",
    "        \n",
    "    # Use TimeSeriesSplit instead of random cv=5\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=tscv, scoring=custom_scorer)\n",
    "    return score.mean()\n",
    "\n",
    "study_lgb = optuna.create_study(direction='maximize')\n",
    "study_lgb.optimize(objective_lgb, n_trials=50)\n",
    "best_params_lgb = study_lgb.best_params\n",
    "best_value_lgb = study_lgb.best_value\n",
    "\n",
    "print(\"Best LightGBM Params:\", best_params_lgb)\n",
    "print(\"Best LightGBM MAE Score:\", -best_value_lgb)  # Convert back to positive MAE\n",
    "print(f\"Best LightGBM MAE: {-best_value_lgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b3842c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-22 18:50:48,516] A new study created in memory with name: no-name-d58858b6-ca7e-456c-8d78-c183447cc8ab\n",
      "[I 2025-08-22 18:52:54,968] Trial 0 finished with value: -8.7498539576803 and parameters: {'iterations': 213, 'depth': 16, 'learning_rate': 0.20139574540297275, 'subsample': 0.9722403483970333, 'colsample_bylevel': 0.6063832525712383}. Best is trial 0 with value: -8.7498539576803.\n",
      "[I 2025-08-22 18:54:20,866] Trial 1 finished with value: -8.732905072668425 and parameters: {'iterations': 272, 'depth': 15, 'learning_rate': 0.18605769092902186, 'subsample': 0.982025879617662, 'colsample_bylevel': 0.8758347896652905}. Best is trial 1 with value: -8.732905072668425.\n",
      "[I 2025-08-22 18:57:11,639] Trial 2 finished with value: -8.701123265458506 and parameters: {'iterations': 296, 'depth': 16, 'learning_rate': 0.1260929193302688, 'subsample': 0.6070362005425208, 'colsample_bylevel': 0.6949846678138509}. Best is trial 2 with value: -8.701123265458506.\n",
      "[I 2025-08-22 18:57:39,471] Trial 3 finished with value: -8.733594853500186 and parameters: {'iterations': 159, 'depth': 14, 'learning_rate': 0.2847658518964813, 'subsample': 0.6895189535013336, 'colsample_bylevel': 0.8176499642770232}. Best is trial 2 with value: -8.701123265458506.\n",
      "[I 2025-08-22 19:00:10,626] Trial 4 finished with value: -8.830888800310726 and parameters: {'iterations': 255, 'depth': 16, 'learning_rate': 0.24928616509071633, 'subsample': 0.739804483276494, 'colsample_bylevel': 0.7676726538309583}. Best is trial 2 with value: -8.701123265458506.\n",
      "[I 2025-08-22 19:00:28,398] Trial 5 finished with value: -8.55119147439349 and parameters: {'iterations': 50, 'depth': 15, 'learning_rate': 0.15813962967129858, 'subsample': 0.672004293536116, 'colsample_bylevel': 0.9013463037807292}. Best is trial 5 with value: -8.55119147439349.\n",
      "[I 2025-08-22 19:00:32,800] Trial 6 finished with value: -8.480595615368307 and parameters: {'iterations': 95, 'depth': 7, 'learning_rate': 0.22503690045986124, 'subsample': 0.7126306551971057, 'colsample_bylevel': 0.6537222169805411}. Best is trial 6 with value: -8.480595615368307.\n",
      "[I 2025-08-22 19:00:53,713] Trial 7 finished with value: -8.555129808351698 and parameters: {'iterations': 66, 'depth': 15, 'learning_rate': 0.11897026424013737, 'subsample': 0.8927873928452892, 'colsample_bylevel': 0.7628515444954858}. Best is trial 6 with value: -8.480595615368307.\n",
      "[I 2025-08-22 19:00:57,739] Trial 8 finished with value: -8.529959616425288 and parameters: {'iterations': 87, 'depth': 3, 'learning_rate': 0.16780654365421688, 'subsample': 0.8832358376627163, 'colsample_bylevel': 0.7867553275155901}. Best is trial 6 with value: -8.480595615368307.\n",
      "[I 2025-08-22 19:01:02,229] Trial 9 finished with value: -8.492185461956456 and parameters: {'iterations': 86, 'depth': 6, 'learning_rate': 0.299994752759809, 'subsample': 0.9710316525683517, 'colsample_bylevel': 0.6850039632025698}. Best is trial 6 with value: -8.480595615368307.\n",
      "[I 2025-08-22 19:01:09,332] Trial 10 finished with value: -8.559818399571128 and parameters: {'iterations': 146, 'depth': 10, 'learning_rate': 0.2263016837754548, 'subsample': 0.8083968906875298, 'colsample_bylevel': 0.6150569814319071}. Best is trial 6 with value: -8.480595615368307.\n",
      "[I 2025-08-22 19:01:13,798] Trial 11 finished with value: -8.478853838151087 and parameters: {'iterations': 116, 'depth': 5, 'learning_rate': 0.2757745339789483, 'subsample': 0.779962240465893, 'colsample_bylevel': 0.6879285477519275}. Best is trial 11 with value: -8.478853838151087.\n",
      "[I 2025-08-22 19:01:18,714] Trial 12 finished with value: -8.482231717943057 and parameters: {'iterations': 121, 'depth': 7, 'learning_rate': 0.2503315910690942, 'subsample': 0.7803794045746034, 'colsample_bylevel': 0.6832618747314843}. Best is trial 11 with value: -8.478853838151087.\n",
      "[I 2025-08-22 19:01:22,941] Trial 13 finished with value: -8.477261860874764 and parameters: {'iterations': 118, 'depth': 5, 'learning_rate': 0.25933459796264846, 'subsample': 0.8181031823643401, 'colsample_bylevel': 0.9747745619540156}. Best is trial 13 with value: -8.477261860874764.\n",
      "[I 2025-08-22 19:01:27,285] Trial 14 finished with value: -8.4606063414402 and parameters: {'iterations': 180, 'depth': 3, 'learning_rate': 0.26868013324455436, 'subsample': 0.8308520219314872, 'colsample_bylevel': 0.9893429767439729}. Best is trial 14 with value: -8.4606063414402.\n",
      "[I 2025-08-22 19:01:31,756] Trial 15 finished with value: -8.464585927690631 and parameters: {'iterations': 200, 'depth': 3, 'learning_rate': 0.2571876693752011, 'subsample': 0.8607849607941518, 'colsample_bylevel': 0.9882867525228581}. Best is trial 14 with value: -8.4606063414402.\n",
      "[I 2025-08-22 19:01:36,492] Trial 16 finished with value: -8.464153995981325 and parameters: {'iterations': 212, 'depth': 3, 'learning_rate': 0.22185005132967223, 'subsample': 0.8803493368976398, 'colsample_bylevel': 0.9949915422749156}. Best is trial 14 with value: -8.4606063414402.\n",
      "[I 2025-08-22 19:01:45,654] Trial 17 finished with value: -8.594244004615994 and parameters: {'iterations': 204, 'depth': 10, 'learning_rate': 0.21794135947174403, 'subsample': 0.9138183367301753, 'colsample_bylevel': 0.9365022751709372}. Best is trial 14 with value: -8.4606063414402.\n",
      "[I 2025-08-22 19:01:53,092] Trial 18 finished with value: -8.555897059782902 and parameters: {'iterations': 232, 'depth': 8, 'learning_rate': 0.23540532597011674, 'subsample': 0.925570112686709, 'colsample_bylevel': 0.8604550738429562}. Best is trial 14 with value: -8.4606063414402.\n",
      "[I 2025-08-22 19:01:57,701] Trial 19 finished with value: -8.464706260711484 and parameters: {'iterations': 183, 'depth': 4, 'learning_rate': 0.20030030471632346, 'subsample': 0.8487144806950639, 'colsample_bylevel': 0.9435314791052077}. Best is trial 14 with value: -8.4606063414402.\n",
      "[I 2025-08-22 19:02:15,831] Trial 20 finished with value: -8.73266592041776 and parameters: {'iterations': 238, 'depth': 12, 'learning_rate': 0.2759788305570863, 'subsample': 0.9392487872738433, 'colsample_bylevel': 0.9995898724737529}. Best is trial 14 with value: -8.4606063414402.\n",
      "[I 2025-08-22 19:02:21,080] Trial 21 finished with value: -8.468690005864651 and parameters: {'iterations': 182, 'depth': 3, 'learning_rate': 0.2618646509218102, 'subsample': 0.853535479398017, 'colsample_bylevel': 0.9979179663015383}. Best is trial 14 with value: -8.4606063414402.\n",
      "[I 2025-08-22 19:02:26,442] Trial 22 finished with value: -8.462983586938053 and parameters: {'iterations': 209, 'depth': 3, 'learning_rate': 0.2404518127035768, 'subsample': 0.8575871865626845, 'colsample_bylevel': 0.9431347901993521}. Best is trial 14 with value: -8.4606063414402.\n",
      "[I 2025-08-22 19:02:31,212] Trial 23 finished with value: -8.47875514310485 and parameters: {'iterations': 159, 'depth': 5, 'learning_rate': 0.23869433477553048, 'subsample': 0.8270664002289799, 'colsample_bylevel': 0.9468435429419205}. Best is trial 14 with value: -8.4606063414402.\n",
      "[I 2025-08-22 19:02:36,248] Trial 24 finished with value: -8.464428093988412 and parameters: {'iterations': 228, 'depth': 4, 'learning_rate': 0.21260345207354975, 'subsample': 0.7674544276325143, 'colsample_bylevel': 0.9111013967708353}. Best is trial 14 with value: -8.4606063414402.\n",
      "[I 2025-08-22 19:02:41,159] Trial 25 finished with value: -8.484745635289059 and parameters: {'iterations': 194, 'depth': 4, 'learning_rate': 0.2976809231185533, 'subsample': 0.8966515842058186, 'colsample_bylevel': 0.9625891742378788}. Best is trial 14 with value: -8.4606063414402.\n",
      "[I 2025-08-22 19:02:46,766] Trial 26 finished with value: -8.497147877847933 and parameters: {'iterations': 161, 'depth': 8, 'learning_rate': 0.1755106292574448, 'subsample': 0.8694323054086396, 'colsample_bylevel': 0.9161550966718469}. Best is trial 14 with value: -8.4606063414402.\n",
      "[I 2025-08-22 19:02:52,776] Trial 27 finished with value: -8.500969635985012 and parameters: {'iterations': 254, 'depth': 6, 'learning_rate': 0.23830172489627421, 'subsample': 0.829140490474441, 'colsample_bylevel': 0.8357582874836087}. Best is trial 14 with value: -8.4606063414402.\n",
      "[I 2025-08-22 19:02:57,211] Trial 28 finished with value: -8.499146117957642 and parameters: {'iterations': 138, 'depth': 3, 'learning_rate': 0.14423446125944694, 'subsample': 0.9442644137552507, 'colsample_bylevel': 0.8773808448144853}. Best is trial 14 with value: -8.4606063414402.\n",
      "[I 2025-08-22 19:03:02,518] Trial 29 finished with value: -8.48798416140138 and parameters: {'iterations': 219, 'depth': 6, 'learning_rate': 0.19396279944189623, 'subsample': 0.7510340888081947, 'colsample_bylevel': 0.9598072499610362}. Best is trial 14 with value: -8.4606063414402.\n",
      "[I 2025-08-22 19:03:07,786] Trial 30 finished with value: -8.460250185403853 and parameters: {'iterations': 212, 'depth': 4, 'learning_rate': 0.21160237675504281, 'subsample': 0.7965025428509023, 'colsample_bylevel': 0.9240343522903348}. Best is trial 30 with value: -8.460250185403853.\n",
      "[I 2025-08-22 19:03:12,770] Trial 31 finished with value: -8.458653857443931 and parameters: {'iterations': 213, 'depth': 4, 'learning_rate': 0.2099163579513301, 'subsample': 0.7929183907449346, 'colsample_bylevel': 0.9192274439171659}. Best is trial 31 with value: -8.458653857443931.\n",
      "[I 2025-08-22 19:03:18,213] Trial 32 finished with value: -8.46910528791458 and parameters: {'iterations': 251, 'depth': 4, 'learning_rate': 0.20849114979809383, 'subsample': 0.794551248843459, 'colsample_bylevel': 0.8885049857626973}. Best is trial 31 with value: -8.458653857443931.\n",
      "[I 2025-08-22 19:03:23,213] Trial 33 finished with value: -8.469992099430957 and parameters: {'iterations': 189, 'depth': 5, 'learning_rate': 0.18847907799291452, 'subsample': 0.8388940922953896, 'colsample_bylevel': 0.9260990632109305}. Best is trial 31 with value: -8.458653857443931.\n",
      "[I 2025-08-22 19:03:28,825] Trial 34 finished with value: -8.470842837074825 and parameters: {'iterations': 272, 'depth': 4, 'learning_rate': 0.20328777241865265, 'subsample': 0.7342731302064938, 'colsample_bylevel': 0.8543071690112939}. Best is trial 31 with value: -8.458653857443931.\n",
      "[I 2025-08-22 19:03:34,142] Trial 35 finished with value: -8.4828073582952 and parameters: {'iterations': 172, 'depth': 7, 'learning_rate': 0.1793482030912833, 'subsample': 0.8057238219870355, 'colsample_bylevel': 0.9663616472602827}. Best is trial 31 with value: -8.458653857443931.\n",
      "[I 2025-08-22 19:03:52,711] Trial 36 finished with value: -8.766923818712295 and parameters: {'iterations': 300, 'depth': 12, 'learning_rate': 0.27271597236209194, 'subsample': 0.6373706257381188, 'colsample_bylevel': 0.8963793158879156}. Best is trial 31 with value: -8.458653857443931.\n",
      "[I 2025-08-22 19:03:57,890] Trial 37 finished with value: -8.483622432316505 and parameters: {'iterations': 216, 'depth': 5, 'learning_rate': 0.24502950419164216, 'subsample': 0.727668039696499, 'colsample_bylevel': 0.927104257324391}. Best is trial 31 with value: -8.458653857443931.\n",
      "[I 2025-08-22 19:04:03,261] Trial 38 finished with value: -8.465875572610823 and parameters: {'iterations': 275, 'depth': 3, 'learning_rate': 0.23221663819008792, 'subsample': 0.7552260846590084, 'colsample_bylevel': 0.826498278716061}. Best is trial 31 with value: -8.458653857443931.\n",
      "[I 2025-08-22 19:04:07,848] Trial 39 finished with value: -8.487484444450015 and parameters: {'iterations': 172, 'depth': 4, 'learning_rate': 0.10474411728331212, 'subsample': 0.7875347952545162, 'colsample_bylevel': 0.9760622745877414}. Best is trial 31 with value: -8.458653857443931.\n",
      "[I 2025-08-22 19:04:14,409] Trial 40 finished with value: -8.476114231306337 and parameters: {'iterations': 247, 'depth': 6, 'learning_rate': 0.16058904963013165, 'subsample': 0.8162467272441649, 'colsample_bylevel': 0.7404917123750164}. Best is trial 31 with value: -8.458653857443931.\n",
      "[I 2025-08-22 19:04:19,154] Trial 41 finished with value: -8.470466572410709 and parameters: {'iterations': 209, 'depth': 3, 'learning_rate': 0.2196920037030495, 'subsample': 0.8894983565822893, 'colsample_bylevel': 0.9454880662165942}. Best is trial 31 with value: -8.458653857443931.\n",
      "[I 2025-08-22 19:04:24,075] Trial 42 finished with value: -8.462298942659356 and parameters: {'iterations': 224, 'depth': 3, 'learning_rate': 0.2256690520912766, 'subsample': 0.870338431756754, 'colsample_bylevel': 0.9811292225131973}. Best is trial 31 with value: -8.458653857443931.\n",
      "[I 2025-08-22 19:04:29,537] Trial 43 finished with value: -8.467630425587341 and parameters: {'iterations': 222, 'depth': 4, 'learning_rate': 0.2098951414393417, 'subsample': 0.8491697063956178, 'colsample_bylevel': 0.9055258677681871}. Best is trial 31 with value: -8.458653857443931.\n",
      "[I 2025-08-22 19:04:34,704] Trial 44 finished with value: -8.467392252326553 and parameters: {'iterations': 269, 'depth': 3, 'learning_rate': 0.28820797328145453, 'subsample': 0.7039838048052509, 'colsample_bylevel': 0.9525248624624559}. Best is trial 31 with value: -8.458653857443931.\n",
      "[I 2025-08-22 19:04:40,708] Trial 45 finished with value: -8.489676189909742 and parameters: {'iterations': 239, 'depth': 5, 'learning_rate': 0.24613368244949163, 'subsample': 0.9064007309089732, 'colsample_bylevel': 0.9774073967622706}. Best is trial 31 with value: -8.458653857443931.\n",
      "[I 2025-08-22 19:04:46,014] Trial 46 finished with value: -8.473893534163995 and parameters: {'iterations': 195, 'depth': 4, 'learning_rate': 0.2304225013015605, 'subsample': 0.8705851284554609, 'colsample_bylevel': 0.8730494724699734}. Best is trial 31 with value: -8.458653857443931.\n",
      "[I 2025-08-22 19:05:00,810] Trial 47 finished with value: -8.713781606698838 and parameters: {'iterations': 206, 'depth': 12, 'learning_rate': 0.265856853558033, 'subsample': 0.8039763512618601, 'colsample_bylevel': 0.9261503136091711}. Best is trial 31 with value: -8.458653857443931.\n",
      "[I 2025-08-22 19:05:05,803] Trial 48 finished with value: -8.46757998804018 and parameters: {'iterations': 227, 'depth': 3, 'learning_rate': 0.1934995208798164, 'subsample': 0.7736785844534829, 'colsample_bylevel': 0.9794402899983223}. Best is trial 31 with value: -8.458653857443931.\n",
      "[I 2025-08-22 19:05:10,976] Trial 49 finished with value: -8.494430374541977 and parameters: {'iterations': 136, 'depth': 7, 'learning_rate': 0.2525952466638416, 'subsample': 0.8348248369132822, 'colsample_bylevel': 0.800499019009504}. Best is trial 31 with value: -8.458653857443931.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CatBoost Params: {'iterations': 213, 'depth': 4, 'learning_rate': 0.2099163579513301, 'subsample': 0.7929183907449346, 'colsample_bylevel': 0.9192274439171659}\n",
      "Best CatBoost MAE Score: 8.458653857443931\n",
      "Best CatBoost MAE: 8.4587\n"
     ]
    }
   ],
   "source": [
    "# Repeat for CatBoost (similar, params: iterations, depth, learning_rate, subsample, colsample_bylevel)\n",
    "def objective_cat(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 50, 300),\n",
    "        'depth': trial.suggest_int('depth', 3, 16),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.1, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.6, 1.0),\n",
    "        'random_state': 42,\n",
    "        'verbose': 0\n",
    "    }\n",
    "    model = CatBoostRegressor(**params)\n",
    "\n",
    "    # CV on logged y, but score on inverse for MAE\n",
    "    def custom_scorer(estimator, X, y):\n",
    "        preds_log = estimator.predict(X)\n",
    "        preds = np.expm1(preds_log)\n",
    "        y_orig = np.expm1(y)s\n",
    "        return -mean_absolute_error(y_orig, preds)  # Neg for minimization\n",
    "        \n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=tscv, scoring=custom_scorer)\n",
    "    return score.mean()\n",
    "\n",
    "study_cat = optuna.create_study(direction='maximize')\n",
    "study_cat.optimize(objective_cat, n_trials=50)\n",
    "best_params_cat = study_cat.best_params\n",
    "best_value_cat = study_cat.best_value\n",
    "\n",
    "print(\"Best CatBoost Params:\", best_params_cat)\n",
    "print(\"Best CatBoost MAE Score:\", -best_value_cat)  # Convert back to positive MAE\n",
    "print(f\"Best CatBoost MAE: {-best_value_cat:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a3781d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step: Retrain tuned models and evaluate\n",
    "tuned_models = {\n",
    "    'Tuned XGBoost': xgb.XGBRegressor(**best_params_xgb),\n",
    "    'Tuned LightGBM': lgb.LGBMRegressor(**best_params_lgb, verbose=-1),\n",
    "    'Tuned CatBoost': CatBoostRegressor(**best_params_cat, verbose=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c50de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to train and evaluate a model\n",
    "def train_evaluate(model, model_name):\n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict (logged scale)\n",
    "    preds_log = model.predict(X_test)\n",
    "    \n",
    "    # Inverse transform to original scale for metrics\n",
    "    preds = np.expm1(preds_log)\n",
    "    y_test_orig = np.expm1(y_test)\n",
    "    \n",
    "    # Metrics\n",
    "    mae = mean_absolute_error(y_test_orig, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_orig, preds))\n",
    "    r2 = r2_score(y_test_orig, preds)\n",
    "    \n",
    "    # Feature importance (for tree-based)\n",
    "    fi = None\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        fi = model.feature_importances_\n",
    "    elif hasattr(model, 'get_feature_importance'):\n",
    "        fi = model.get_feature_importance()\n",
    "\n",
    "    if fi is not None:\n",
    "        feature_names = X_train.columns if isinstance(X_train, pd.DataFrame) else [f\"f{i}\" for i in range(X_train.shape[1])]\n",
    "        importances = pd.Series(fi, index=feature_names).sort_values(ascending=False)\n",
    "        print(f\"\\nTop 5 Features for {model_name}:\\n{importances.head()}\")\n",
    "    \n",
    "    return {'Model': model_name, 'MAE': mae, 'RMSE': rmse, 'R2': r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0e03cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Features for Tuned XGBoost:\n",
      "f38    0.154879\n",
      "f32    0.116662\n",
      "f42    0.111875\n",
      "f40    0.109052\n",
      "f29    0.081925\n",
      "dtype: float32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Features for Tuned LightGBM:\n",
      "f0     203\n",
      "f20     65\n",
      "f21     45\n",
      "f1      44\n",
      "f22     43\n",
      "dtype: int32\n",
      "\n",
      "Top 5 Features for Tuned CatBoost:\n",
      "f38    13.037677\n",
      "f32    12.575601\n",
      "f42    10.292195\n",
      "f40    10.023203\n",
      "f29     8.121683\n",
      "dtype: float64\n",
      "\n",
      "Tuned Model Comparison:\n",
      "            Model       MAE       RMSE        R2\n",
      "0   Tuned XGBoost  7.982738  11.081593  0.687961\n",
      "1  Tuned LightGBM  8.005724  11.090762  0.687445\n",
      "2  Tuned CatBoost  7.974690  11.076789  0.688232\n"
     ]
    }
   ],
   "source": [
    "tuned_results = []\n",
    "for name, model in tuned_models.items():\n",
    "    tuned_results.append(train_evaluate(model, name))  # Reuse function from base\n",
    "\n",
    "tuned_df = pd.DataFrame(tuned_results)\n",
    "print(\"\\nTuned Model Comparison:\")\n",
    "print(tuned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25c93be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CatBoost model saved to 'best_catboost_model.pkl'\n",
      "Best CatBoost parameters saved to 'best_catboost_params.pkl'\n",
      "\n",
      "Saved model: CatBoostRegressor\n",
      "Model parameters: {'iterations': 213, 'depth': 4, 'learning_rate': 0.2099163579513301, 'subsample': 0.7929183907449346, 'colsample_bylevel': 0.9192274439171659}\n",
      "Model performance - MAE: 7.974690, RMSE: 11.076789, R2: 0.688232\n"
     ]
    }
   ],
   "source": [
    "# Save the best tuned CatBoost model to pickle file\n",
    "import pickle\n",
    "\n",
    "# Get the best CatBoost model (which is already trained from the evaluation loop)\n",
    "best_catboost_model = tuned_models['Tuned CatBoost']\n",
    "\n",
    "# Save the model to a pickle file\n",
    "with open('best_catboost_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_catboost_model, f)\n",
    "\n",
    "print(\"Best CatBoost model saved to 'best_catboost_model.pkl'\")\n",
    "\n",
    "# Also save the best parameters for reference\n",
    "with open('best_catboost_params.pkl', 'wb') as f:\n",
    "    pickle.dump(best_params_cat, f)\n",
    "\n",
    "print(\"Best CatBoost parameters saved to 'best_catboost_params.pkl'\")\n",
    "\n",
    "# Display the saved model info\n",
    "print(f\"\\nSaved model: {type(best_catboost_model).__name__}\")\n",
    "print(f\"Model parameters: {best_params_cat}\")\n",
    "print(f\"Model performance - MAE: {7.974690:.6f}, RMSE: {11.076789:.6f}, R2: {0.688232:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c0bf8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model Performance Comparison:\n",
      "MAE: 7.974690\n",
      "RMSE: 11.076789\n",
      "R2: 0.688232\n",
      "\n",
      "First 10 Predictions vs Actual Values:\n",
      "Predicted\tActual\t\tDifference\n",
      "--------------------------------------------------\n",
      "25.2032\t\t21.0000\t\t+4.2032\n",
      "25.2032\t\t21.0000\t\t+4.2032\n",
      "26.8380\t\t23.0000\t\t+3.8380\n",
      "34.6309\t\t33.0000\t\t+1.6309\n",
      "31.6658\t\t27.0000\t\t+4.6658\n",
      "36.9934\t\t27.0000\t\t+9.9934\n",
      "31.6658\t\t32.0000\t\t-0.3342\n",
      "36.9934\t\t48.0000\t\t-11.0066\n",
      "27.8805\t\t21.0000\t\t+6.8805\n",
      "70.0051\t\t90.0000\t\t-19.9949\n",
      "\n",
      "Comparison Summary:\n",
      "Total samples: 40739\n",
      "Mean absolute error: 7.974690\n",
      "Standard deviation of errors: 11.076896\n",
      "Min error: -60.203295\n",
      "Max error: 51.751484\n",
      "\n",
      "First 5 rows of detailed comparison:\n",
      "   Actual  Predicted  Difference  Absolute_Error\n",
      "0    21.0  25.203200    4.203200        4.203200\n",
      "1    21.0  25.203200    4.203200        4.203200\n",
      "2    23.0  26.837983    3.837983        3.837983\n",
      "3    33.0  34.630884    1.630884        1.630884\n",
      "4    27.0  31.665830    4.665830        4.665830\n"
     ]
    }
   ],
   "source": [
    "# ... existing code ...\n",
    "\n",
    "# Load the saved best CatBoost model and compare predictions with y_test\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the saved model\n",
    "with open('best_catboost_model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "# Make predictions\n",
    "predictions_log = loaded_model.predict(X_test)\n",
    "\n",
    "# Convert predictions back to original scale (since y_train was log-transformed)\n",
    "predictions = np.expm1(predictions_log)\n",
    "y_test_orig = np.expm1(y_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test_orig, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_orig, predictions))\n",
    "r2 = r2_score(y_test_orig, predictions)\n",
    "\n",
    "print(\"Loaded Model Performance Comparison:\")\n",
    "print(f\"MAE: {mae:.6f}\")\n",
    "print(f\"RMSE: {rmse:.6f}\")\n",
    "print(f\"R2: {r2:.6f}\")\n",
    "\n",
    "# Compare first 10 predictions vs actual values\n",
    "print(f\"\\nFirst 10 Predictions vs Actual Values:\")\n",
    "print(\"Predicted\\tActual\\t\\tDifference\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(min(10, len(predictions))):\n",
    "    pred = predictions[i]\n",
    "    actual = y_test_orig[i]\n",
    "    diff = pred - actual\n",
    "    print(f\"{pred:.4f}\\t\\t{actual:.4f}\\t\\t{diff:+.4f}\")\n",
    "\n",
    "# Create a comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual': y_test_orig,\n",
    "    'Predicted': predictions,\n",
    "    'Difference': predictions - y_test_orig,\n",
    "    'Absolute_Error': np.abs(predictions - y_test_orig)\n",
    "})\n",
    "\n",
    "print(f\"\\nComparison Summary:\")\n",
    "print(f\"Total samples: {len(comparison_df)}\")\n",
    "print(f\"Mean absolute error: {comparison_df['Absolute_Error'].mean():.6f}\")\n",
    "print(f\"Standard deviation of errors: {comparison_df['Difference'].std():.6f}\")\n",
    "print(f\"Min error: {comparison_df['Difference'].min():.6f}\")\n",
    "print(f\"Max error: {comparison_df['Difference'].max():.6f}\")\n",
    "\n",
    "# Show the first few rows of the comparison\n",
    "print(f\"\\nFirst 5 rows of detailed comparison:\")\n",
    "print(comparison_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6e877b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datavenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
